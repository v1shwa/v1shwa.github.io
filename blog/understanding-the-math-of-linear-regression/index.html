<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
    <!-- Replacing this with jekyll-seo-tag -->

<!-- begin SEO -->









<title>Understanding the math behind Linear Regression - Vishwa</title>




<meta name="description" content="Basics and mathematical proof of Simple Linear Regression">



<meta name="author" content="Vishwa">

<meta property="og:locale" content="en">
<meta property="og:site_name" content="Vishwa">
<meta property="og:title" content="Understanding the math behind Linear Regression">


  <link rel="canonical" href="https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/">
  <meta property="og:url" content="https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/">



  <meta property="og:description" content="Basics and mathematical proof of Simple Linear Regression">



  <meta name="twitter:site" content="@v1shwa">
  <meta name="twitter:title" content="Understanding the math behind Linear Regression">
  <meta name="twitter:description" content="Basics and mathematical proof of Simple Linear Regression">
  <meta name="twitter:url" content="https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/">

  <meta name="twitter:card" content="summary">
  
    <meta name="twitter:image" content="https://v1shwa.github.io/">
  
  <meta name="twitter:creator" content="@v1shwa">



  <meta property="og:image" content="https://v1shwa.github.io/">



  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-09-16T00:00:00+05:30">






    
    <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Vishwa Feed">

    <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <script>
      document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    </script>

    <!-- For all browsers -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Raleway|Gochi+Hand|Heebo:100,300,400,500,700,800,900" rel="stylesheet">
    <link rel="stylesheet" href="https://v1shwa.github.io/assets/css/main.css">
    
    <link rel="shortcut icon" type="image/x-icon" href="https://v1shwa.github.io/assets/images/favicon.png">
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/images/icons/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/images/icons/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/images/icons/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/images/icons/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/images/icons/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/images/icons/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/images/icons/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/images/icons/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/images/icons/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="/assets/images/icons/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="512x512" href="/assets/images/icons/android-icon-512x512.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/images/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/assets/images/icons/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/assets/images/icons/favicon-16x16.png">
    
    <link rel="manifest" href="/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/assets/images/icons/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">

    <meta http-equiv="cleartype" content="on">
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
  </head>

  <body class="layout--post">

    <div class="topnav">
  

  <div class="topnav__content">
    <h3 class="site__name">Vishwa</h3>
    

    <nav>
      <ul id="navigation" class="links slimmenu">
        
          
          <li class="menu-item">
            <a href="https://v1shwa.github.io/">home</a>
            
          </li>
        
          
          <li class="menu-item">
            <a href="https://v1shwa.github.io/blog">blog</a>
            
          </li>
        
          
          <li class="menu-item">
            <a href="https://v1shwa.github.io/projects">projects</a>
            
          </li>
        
          
          <li class="menu-item">
            <a href="https://v1shwa.github.io/about">about</a>
            
          </li>
        
      </ul>
    </nav>
  </div>
</div>
<!-- 

<nav class="breadcrumbs">
  <ol itemscope itemtype="http://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
          <a href="https://v1shwa.github.io/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="http://schema.org/ListItem">
          <a href="https://v1shwa.github.io/blog" itemprop="item"><span itemprop="name">Blog</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Understanding the math behind Linear Regression</li>
      
    
  </ol>
</nav> -->

<div id="main" role="main">
  <article class="post" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Understanding the math behind Linear Regression">
    <meta itemprop="description" content="Inside the Post">
    <meta itemprop="datePublished" content="September 16, 2017">
    
  
    <div class="post__inner-wrap">
        <h1 class="post__title" itemprop="headline">Understanding the math behind Linear Regression
</h1>
        
        
        <p class="post__meta">Published on <time datetime="2017-09-16T00:00:00+05:30">September 16, 2017 </time></p>
        
      </header>
        
      <!-- Tags -->
      <span class="v-tags">
        
          
          <a href="/tag/machine-learning" title="View all posts tagged machine-learning"><code class="highligher-rouge"><nobr>#machine-learning</nobr></code>&nbsp;</a>
        
          
          <a href="/tag/rawml" title="View all posts tagged rawml"><code class="highligher-rouge"><nobr>#rawml</nobr></code>&nbsp;</a>
        
      </span>

      <section class="post__content" itemprop="text">
        <h2 class="no_toc" id="inside-the-post">Inside the Post</h2>
<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#what-is-linear-regression" id="markdown-toc-what-is-linear-regression">What is Linear Regression</a></li>
  <li><a href="#the-perfect-regression-line" id="markdown-toc-the-perfect-regression-line">The Perfect Regression Line</a></li>
  <li><a href="#derivation-of-least-squares-estimates" id="markdown-toc-derivation-of-least-squares-estimates">Derivation of Least squares estimates</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>Linear regression is an almost <a href="https://en.wikipedia.org/wiki/Regression_analysis#History">200 years old</a> simple but one of the most useful statistical models. It is used to analyze the relationship between two or more continuous variables in a dataset.</p>

<p>The goal of this article is to understand what linear regression is &amp; all the math that powers the model.</p>

<h2 id="what-is-linear-regression">What is Linear Regression</h2>

<p>Linear Regression is a statistical method that attempts to model a relationship between two or more variables by fitting a <em>line</em> along the observed data. This <em>line</em> is called as the <strong>regression line</strong>.</p>

<p>As for every linear equation, the equation for the regression line can be written as,</p>

<script type="math/tex; mode=display">y = b_0 + b_1X</script>

<p>where,</p>

<ul>
  <li><script type="math/tex">y</script> is called as the <strong>dependent</strong> or <strong>output/target</strong> variable,</li>
  <li><script type="math/tex">X</script> is called as the <strong>independent</strong> variable or <strong>predictor</strong> or <strong>input</strong> variable,</li>
  <li><script type="math/tex">b_0, b_1</script> are the unknown constants called as <em>Y-intercept</em> and <em>slope</em> respectively, which we’ll have to estimate.</li>
</ul>

<p><strong><u>Note</u></strong>: If we have more than 1 predictors in the model, then this would be called <strong>Multiple Linear Regression</strong> and its equation would be like this,</p>

<p>​   <script type="math/tex">y = b_0 + b_1X_1 + b_2X_2 + b_3X_3 + ...</script></p>

<h2 id="the-perfect-regression-line">The Perfect Regression Line</h2>

<p><img src="https://i.imgur.com/qlc2Hu4.png" alt="" /></p>

<p>In a practical world, it’s nearly impossible to find the ideal regression line that covers all the data points (see picture above). So, instead, what we do is, identify the best equation that covers all the points with least errors. We call this line, the <strong>best fitting line</strong>.</p>

<p>To calculate the error, we take the sum of difference between the <em>estimated target values <script type="math/tex">(\hat{y_i})</script></em> and <em>actual target values<script type="math/tex">(y_i)</script></em> for all points in the dataset. To normalize the negative errors, we’ll consider the squares of the errors. Now, we can formulate the error as,</p>

<p>​               <script type="math/tex">Error(E) = \sum(\hat{y_i}-y_i)^2</script></p>

<p>This technique is called the <strong>Least Squares technique</strong>.</p>

<p>From the definition of linear regression, we can replace the <script type="math/tex">y_i</script> with <script type="math/tex">b_0 + b_1X_i</script>,</p>

<p>​               <script type="math/tex">E = \sum(\hat{y_i} - (b_0 + b_1X_i))^2</script></p>

<p>​                   <em>or</em></p>

<p>​               <script type="math/tex">E =  \sum(\hat{y_i} - b_0 - b_1X_i)^2</script></p>

<p>Now, our  immediate aim is to identify the ideal values for the parameters <script type="math/tex">b_0</script> and  <script type="math/tex">b_1</script>, such that the value of <em>Error</em> function is minimized as much as possible. Let’s derive that.</p>

<h2 id="derivation-of-least-squares-estimates">Derivation of Least squares estimates</h2>

<p>What’s the first thing that comes to our mind when someone says maxima/minima of a function? — you guessed it — <em>Partial Derivates</em>.</p>

<p>To find the relative minima of a function, let’s take the derivate of <em>Error function</em> on both the parameters <script type="math/tex">b_0</script> &amp; <script type="math/tex">b_1</script> and equate them to zero.</p>

<p><em>Note: For the sake of simplicity, I’ll represent the <script type="math/tex">\sum_{i=1}^{n}</script> as just <script type="math/tex">\sum</script> from hereon.</em></p>

<p><strong>(i) Derivative of E on <script type="math/tex">b_1</script>:</strong></p>

<script type="math/tex; mode=display">=> \frac{\partial{E}}{\partial{b_1}} \equiv 2 \sum(y_i - b_0 - b_1X_i)(-1) = 0 \\[1cm]
=> \sum(y_i) - \sum(b_0) - \sum(b_1X_i) = 0 \\[1cm]
=>  b_0 = \frac{\sum(y_i) - b_1\sum(X_i)}{n}    \longrightarrow (i)</script>

<p><strong>(ii) Derivative of E on <script type="math/tex">b_0</script>:</strong></p>

<script type="math/tex; mode=display">=> \frac{\partial{E}}{\partial{b_0}} \equiv 2 \sum(y_i - b_0 - b_1X_i)(X_i) = 0 \\[1cm]

=> \sum(X_iy_i) - b_0\sum(X_i) - b_1\sum(X_i^2) = 0 \\[1cm]

Substituting\ the\ value\ of\ b_0\ from\ (i),  \\[1cm]
=> \sum(X_iy_i) - \frac{\sum(y_i) - b_1\sum(X_i)}{n}\sum(X_i) - b_1\sum(X_i^2) = 0 \\[1cm]

Multiplying\ with\ ‘n‘\ on\ both\ sides, \\[1cm]

=> n\sum(X_iy_i) - \sum(X_i)\sum(y_i) - nb_1\sum(X_i^2) + b_1(\sum(X_i))^2= 0\\[1cm]


Solving\ for\ b_1,\ we\ get,\\[1cm]

b_1 = \frac{n\sum(X_iy_i) - \sum(X_i)\sum(y_i)}{n\sum(X_i^2) - (\sum(X_i))^2} \\[1cm]</script>

<p>Now, by substituting this value of <script type="math/tex">b_1</script> in the <script type="math/tex">(i)</script>, we can also get the value of <script type="math/tex">b_0</script>,</p>

<script type="math/tex; mode=display">b_0 = \frac{\sum(y_i) - \frac{n\sum(X_iy_i) - \sum(X_i)\sum(y_i)}{n\sum(X_i^2) - (\sum(X_i))^2} \sum(X_i)}{n} \\[1cm]

or,\ for\ simplicity,\ let's\ just\ keep\ it, \\[1cm]
    
b_0 = \frac{\sum(y_i) - b_1\sum(X_i)}{n}</script>

<h2 id="conclusion">Conclusion</h2>

<p>Thus, the <em>best fitting line</em> in simple linear regression is <script type="math/tex">y = b_0 + b_1X</script>,  where, 
<script type="math/tex">b_1 = \frac{n\sum(X_iy_i) - \sum(X_i)\sum(y_i)}{n\sum(X_i^2) - (\sum(X_i))^2}</script> and <script type="math/tex">b_0 = \frac{\sum(y_i) - b_1\sum(X_i)}{n}</script> .</p>

        
        <section class="page__share">
<ul class="rrssb-buttons clearfix">
    <li class="rrssb-facebook">
      <!--  Replace with your URL. For best results, make sure you page has the proper FB Open Graph tags in header:
            https://developers.facebook.com/docs/opengraph/howtos/maximizing-distribution-media-content/ -->
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/" class="popup">
        <span class="rrssb-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 29 29"><path d="M26.4 0H2.6C1.714 0 0 1.715 0 2.6v23.8c0 .884 1.715 2.6 2.6 2.6h12.393V17.988h-3.996v-3.98h3.997v-3.062c0-3.746 2.835-5.97 6.177-5.97 1.6 0 2.444.173 2.845.226v3.792H21.18c-1.817 0-2.156.9-2.156 2.168v2.847h5.045l-.66 3.978h-4.386V29H26.4c.884 0 2.6-1.716 2.6-2.6V2.6c0-.885-1.716-2.6-2.6-2.6z"/></svg>
        </span>
        <span class="rrssb-text">Facebook</span>
      </a>
    </li>

    <li class="rrssb-twitter">
      <!-- Replace href with your Meta and URL information  -->
      <a href="https://twitter.com/intent/tweet?via=v1shwa&text=Understanding the math behind Linear Regression https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/"
      class="popup">
        <span class="rrssb-icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 28"><path d="M24.253 8.756C24.69 17.08 18.297 24.182 9.97 24.62a15.093 15.093 0 0 1-8.86-2.32c2.702.18 5.375-.648 7.507-2.32a5.417 5.417 0 0 1-4.49-3.64c.802.13 1.62.077 2.4-.154a5.416 5.416 0 0 1-4.412-5.11 5.43 5.43 0 0 0 2.168.387A5.416 5.416 0 0 1 2.89 4.498a15.09 15.09 0 0 0 10.913 5.573 5.185 5.185 0 0 1 3.434-6.48 5.18 5.18 0 0 1 5.546 1.682 9.076 9.076 0 0 0 3.33-1.317 5.038 5.038 0 0 1-2.4 2.942 9.068 9.068 0 0 0 3.02-.85 5.05 5.05 0 0 1-2.48 2.71z"/></svg></span>
        <span class="rrssb-text">Twitter</span>
      </a>
    </li>

    <li class="rrssb-linkedin">
      <!-- Replace href with your meta and URL information -->
      <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/" class="popup">
        <span class="rrssb-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 28"><path d="M25.424 15.887v8.447h-4.896v-7.882c0-1.98-.71-3.33-2.48-3.33-1.354 0-2.158.91-2.514 1.802-.13.315-.162.753-.162 1.194v8.216h-4.9s.067-13.35 0-14.73h4.9v2.087c-.01.017-.023.033-.033.05h.032v-.05c.65-1.002 1.812-2.435 4.414-2.435 3.222 0 5.638 2.106 5.638 6.632zM5.348 2.5c-1.676 0-2.772 1.093-2.772 2.54 0 1.42 1.066 2.538 2.717 2.546h.032c1.71 0 2.77-1.132 2.77-2.546C8.056 3.593 7.02 2.5 5.344 2.5h.005zm-2.48 21.834h4.896V9.604H2.867v14.73z"/></svg>
        </span>
        <span class="rrssb-text">LinkedIn</span>
      </a>
    </li>

    <li class="rrssb-googleplus">
      <!-- Replace href with your meta and URL information.  -->
      <a href="https://plus.google.com/share?url=https://v1shwa.github.io/blog/understanding-the-math-of-linear-regression/" class="popup">
        <span class="rrssb-icon">
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M21 8.29h-1.95v2.6h-2.6v1.82h2.6v2.6H21v-2.6h2.6v-1.885H21V8.29zM7.614 10.306v2.925h3.9c-.26 1.69-1.755 2.925-3.9 2.925-2.34 0-4.29-2.016-4.29-4.354s1.885-4.353 4.29-4.353c1.104 0 2.014.326 2.794 1.105l2.08-2.08c-1.3-1.17-2.924-1.883-4.874-1.883C3.65 4.586.4 7.835.4 11.8s3.25 7.212 7.214 7.212c4.224 0 6.953-2.988 6.953-7.082 0-.52-.065-1.104-.13-1.624H7.614z"/></svg>            </span>
        <span class="rrssb-text">Google+</span>
      </a>
    </li>
</ul>
</section>

      
      </section>

    </div>

    
      <div class="page__comments">

  
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'v1shwa-github-io';
      var disqus_url = 'https://v1shwa.github.io//blog/understanding-the-math-of-linear-regression/';

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  
</div>

    


  </article>
</div>


    <div class="page__footer">
      <footer>
        <div class="page__footer-copyright">
          <a href="https://github.com/v1shwa" target="_blank" title="Github" rel="noopener"><i class="fa fa-github-square fa-2x" style="color: #000000" aria-hidden="true"></i></a>
          <a href="https://twitter.com/v1shwa" target="_blank" title="Twitter" rel="noopener"><i class="fa fa-twitter-square fa-2x" style="color: #1da1f3;" aria-hidden="true"></i></a>
          <a href="/feed.xml" target="_blank" title="XML Feed" rel="noopener"><i class="fa fa-rss-square fa-2x" style="color: #fb9e3a;" aria-hidden="true"></i></a>
          <i>&copy; 2017 Vishwa</i>
        </div>
      </footer>
    </div>
    
    <script src="https://v1shwa.github.io/assets/js/plugins/jquery-1.12.4.min.js"></script>
    <script src="https://v1shwa.github.io/assets/js/plugins/rrssb.min.js"></script>
    <script src="https://v1shwa.github.io/assets/js/slimmenu.js"></script>
    <script src="https://v1shwa.github.io/assets/js/main.js"></script>
  
    

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-71763469-3', 'auto');
  ga('send', 'pageview');
</script>



    <script src="https://v1shwa.github.io/assets/js/manup.js"></script>
    <script>
      if (navigator.serviceWorker.controller) {
        console.log('[PWA] active service worker found, no need to register')
      } else {
        //Register the ServiceWorker
        navigator.serviceWorker.register('sw.js', {
          scope: './'
        }).then(function(reg) {
          console.log('Service worker has been registered for scope: '+ reg.scope);
        });
      }
    </script>
  </body>
</html>
